V <- s$v #extract the right singular vectors
D <- diag(s$d) #convert the vector of singular values s$d into a diagonal matrix D. The off-diagonal elements are zeros
# We can reconstruct the original matrix Y to check if SVD did the right thing
Yhat <- U %*% D %*% t(V)
resid <- Y - Yhat #calculate residuals (differences between the original matrix Y and the reconstructed matrix Yhat)
max(abs(resid)) #find the maximum value among all the absolute residuals, which represents the largest deviation between the original and reconstructed matrices. Ideally this should be very close to zero
plot(s$d) #plotting the values we can see that there are some that are zeros, so we can make some dimensional reductions
# We can remove the last 4 columns to get rid of some dimensions
k <- ncol(U)-4
Yhat <- U[,1:k] %*% D[1:k,1:k] %*% t(V[1:k]) #recontstuct Yhat by selecting k submatrix
Yhat <- U[,1:k] %*% D[1:k,1:k] %*% t(V[,1:k]) #recontsruct Yhat by selecting k submatrix
resid <- Y - Yhat
max(abs(resid))
# The entries of d tell us the proportion of variance that is explained by that particular column
plot( s$d / sum(s$d^2)* 100)
# The entries of d tell us the proportion of variance that is explained by that particular column
plot( s$d^2 / sum(s$d^2)* 100)
# We can remove half of the data
k <- ncol(U)-95
Yhat <- U[,1:k] %*% D[1:k,1:k] %*% t(V[,1:k]) #reconstruct Yhat by selecting k submatrix
resid <- Y - Yhat
boxplot(resid, ylim=LIM)
# We can answer what percent we keep by
var(as.vector(resid))/var(as.vector(Y))
1-var(as.vector(resid))/var(as.vector(Y))
# We can also check like this
sum(s$d[1:k]^2/sum(s$d^2)
# We can also check like this
sum(s$d[1:k]^2/sum(s$d^2))
(s$d[1:k]^2/sum(s$d^2))
sum(s$d[1:k]^2/sum(s$d^2))
library(tissuesGeneExpression)
data(tissuesGeneExpression)
# Compute the SVD of e
s = svd(e)
# Now compute the mean of each row
m = rowMeans(e)
cor(s$u[,1],m)
newmeans = rnorm(nrow(e)) ##random values we will add to create new means
newe = e+newmeans ##we change the means
sqrt(crossprod(e[,3]-e[,45]))
sqrt(crossprod(newe[,3]-newe[,45]))
y = e - rowMeans(e)
s = svd(y)
resid = y - s$u %*% diag(s$d) %*% t(s$v)
max(abs(resid))
x=matrix(rep(c(1,2),each=5),5,2)
x
x*c(1:5)
sweep(x,1,1:5,"*")
# Which of the following gives us the same as diag(s$d)%*%t(s$v) ?
diag(s$d)%*%t(s$v)
# Which of the following gives us the same as diag(s$d)%*%t(s$v) ?
1-diag(s$d)%*%t(s$v)
# Which of the following gives us the same as diag(s$d)%*%t(s$v) ?
diag(s$d)%*%t(s$v)
s$d * t(s$v)
s$v % s$d
s$v * s$d
t(s$d * s$v)
s$d %*% t(s$v)[,1]
str(s$d)
str(s$v)
str(s$u)
is.matrix(s%d)
is.matrix(s$d)
is.matrix(s$v)
is.matrix(s$u)
# Let z = s$d * t(s$v). We showed a derivation demonstrating that because U is orthogonal,
# the distance between e[,3] and e[,45] is the same as the distance between y[,3] and y[,45],
# which is the same as z[,3] and z[,45]:
z = s$d * t(s$v)
sqrt(crossprod(e[,3]-e[,45]))
sqrt(crossprod(y[,3]-y[,45]))
sqrt(crossprod(z[,3]-z[,45]))
# What is the difference (in absolute value) between the actual distance
# sqrt(crossprod(e[,3]-e[,45])) and the approximation using only two dimensions of z?
z_2d <- z[1:2, ]
e_approx_3 <- s$u[, 1:2] %*% z_approx[, 3]
e_approx_45 <- s$u[, 1:2] %*% z_approx[, 45]
e_approx_3 <- s$u[, 1:2] %*% z_2d[, 3]
e_approx_45 <- s$u[, 1:2] %*% z_2d[, 45]
approx_distance <- sqrt(crossprod(e_approx_3 - e_approx_45))
abs(actual_distance - approx_distance)
abs(sqrt(crossprod(e[,3]-e[,45])) - approx_distance)
# What is the difference (in absolute value) between the actual distance
# sqrt(crossprod(e[,3]-e[,45])) and the approximation using only two dimensions of z?
realdistance = sqrt(crossprod(e[,3]-e[,45]))
approxdistance = sqrt(crossprod(z[1:2,3]-z[1:2,45]))
abs(realdistance - approxdistance)
#5# What is the minimum number of dimensions we need to use for the approximation
# in SVD Exercises #4 to be within 10% or less?
ks = 1:189
realdistance = sqrt(crossprod(e[,3]-e[,45]))
approxdistances = sapply(ks,function(k){
sqrt(crossprod(z[1:k,3,drop=FALSE]-z[1:k,45,drop=FALSE] ))
})
percentdiff = 100*abs(approxdistances - realdistance)/realdistance
plot(ks,percentdiff) ##take a look
min(ks[which(percentdiff < 10)])
install.packages("httr")
install.packages("xml2")
install.packages("tidyverse")
library(tidyverse)
library(httr) #enables interaction with the NCBI E-utilities API
library(xml2) #enables to extract info from XML formats
head("influenza_a_virus.fasta")
query <- "Influenza A virus[ORGANISM] AND 8000:20000[Sequence Length]"
ids <- search_ncbi(query, retmax = 10)
setwd("~/Downloads")
library(knitr)
library(VariantAnnotation)
library(tidyverse)
source(params$ext_funcs)
vcf <- readVcf(params$vcf)
head(rowRanges(vcf))
head(info(vcf))
head(geno(vcf)$GT)
View(vcf)
variants <- rowRanges(vcf)
variants$`REF` <- as.character(variants$`REF`)
variants$ALT <- sapply(variants$ALT, function(x) as.character(x)[1])
variants <- as_tibble(variants)
variants$variantName = names(rowRanges(vcf))
variants = cbind(variants, as_tibble(geno(vcf)$GT))
names(variants)[names(variants) == "patient_01_sample_01"] <- "case_case1"
names(variants)[names(variants) == "patient_02_sample_02"] <- "control_control1"
variants$gene <- unlist(lapply(info(vcf)$ANN, get_most_severe_gene))
variants$ens <- unlist(lapply(info(vcf)$ANN, get_most_severe_ens))
variants$transcript <- unlist(lapply(info(vcf)$ANN, get_most_severe_tr))
variants$aa_change <- unlist(lapply(info(vcf)$ANN, get_most_severe_aa_change))
variants$consequence <- unlist(lapply(info(vcf)$ANN, get_most_severe_consequence))
variants$impact <- unlist(lapply(info(vcf)$ANN, get_most_severe_impact))
View(variants)
variants %>%
filter(!is.na(consequence)) %>%
count(consequence) %>%
mutate(count = n,
percent = paste0(round(count/sum(count) * 100, digits = 2), "%"))%>%
arrange(desc(count)) %>%
mutate(lab.ypos = cumsum(count) - 0.5 * count) %>%
ggplot(aes(x="", y=count, fill=consequence))+
geom_bar(width = 1, stat = "identity")+
coord_polar(theta = "y")+
ggrepel::geom_text_repel(aes(y=lab.ypos, label=percent), max.overlaps = Inf)+
theme_void()
variants %>%
filter(!is.na(consequence)) %>%
group_by(consequence) %>%
summarise(count=n()) %>%
arrange(desc(count)) %>%
kable()
selectedVars <- filteredVars %>%
dplyr::select(seqnames, start, REF, ALT, gene, consequence, aa_change)
filteredVars = variants %>%
filter(control_control1 == "0/0" &
(impact == "MODERATE" | impact == "HIGH") &
# ens %in% significant_de_genes &
consequence == "missense_variant")
filteredVars <- as_tibble(filteredVars)
View(filteredVars)
selectedVars <- filteredVars %>%
dplyr::select(seqnames, start, REF, ALT, gene, consequence, aa_change)
selectedVars_table <- selectedVars
selectedVars_table %>% knitr::kable()
# create table for VEP
VEP.tab <- filteredVars %>%
dplyr::select(seqnames, start, REF, ALT) %>%
mutate(ID = ".",  .after = start) %>%
mutate(seqnames = substr(seqnames, 4, nchar(.))) # all are from chromosome 21 and VEP does not accept "chr"
write.table(VEP.tab, "table_to_VEP.txt", col.names = F, row.names = F, quote = FALSE)
VEP.res <- read.table("heTqTeW6D9L4Am4S.txt", header = T, sep ='\t',comment.char = "")
selectedVars_table <- VEP.res %>% filter(am_class %in% c("ambiguous", "likely_pathogenic"))
selectedVars_table %>%
select(Location, Consequence, SYMBOL, SIFT, PolyPhen, am_class, am_pathogenicity, LOEUF) %>%
knitr::kable()
write.table(selectedVars_table, "VEP_filtered_results_ex1_test.txt", row.names = F, quote = FALSE)
library(seqinr)
library(dplyr)
# Function to count Ns in sequences
count_Ns <- function(fasta_file) {
sequences <- read.fasta(fasta_file)  # Read the FASTA file
Ns_count <- sapply(sequences, function(seq) sum(toupper(seq) == "N"))  # Count 'N's in each sequence
return(Ns_count)
}
# Load all downloaded FASTA files
fasta_files <- list.files(path = "/Users/pablo/R/viralingo/nscounts_family_distribution/sequences", pattern = "*.fasta", full.names = TRUE)
# Initialize a list to store results
results <- list()
# Loop through each file and process
for (file in fasta_files) {
Ns_count <- count_Ns(file)  # Get the count of 'N's in each sequence
sequence_headers <- names(read.fasta(file))  # Get the headers (virus family info should be here)
# Categorize sequences based on Ns count
quality <- sapply(Ns_count, categorize_quality)
# Extract viral family information from headers
family <- gsub(" .*", "", sequence_headers)
# Combine results into a data frame
file_results <- data.frame(file = rep(file, length(Ns_count)),
family = family,
Ns_count = Ns_count,
quality = quality)
# Append to results list
results[[file]] <- file_results
}
# Loop through each file and process
for (file in fasta_files) {
Ns_count <- count_Ns(file)  # Get the count of 'N's in each sequence
sequence_headers <- names(read.fasta(file))  # Get the headers (virus family info should be here)
# Extract viral family information from headers
family <- gsub(" .*", "", sequence_headers)
# Combine results into a data frame
file_results <- data.frame(file = rep(file, length(Ns_count)),
family = family,
Ns_count = Ns_count,
quality = quality)
# Append to results list
results[[file]] <- file_results
}
# Loop through each file and process
for (file in fasta_files) {
Ns_count <- count_Ns(file)  # Get the count of 'N's in each sequence
sequence_headers <- names(read.fasta(file))  # Get the headers (virus family info should be here)
# Extract viral family information from headers
family <- gsub(" .*", "", sequence_headers)
# Combine results into a data frame
file_results <- data.frame(file = rep(file, length(Ns_count)),
family = family,
Ns_count = Ns_count)
# Append to results list
results[[file]] <- file_results
}
# Combine all results into one data frame
all_data <- bind_rows(results)
# Summarize the data by family
family_summary <- all_data %>%
group_by(family) %>%
summarise(
num_sequences = n(),
mean_N_count = mean(Ns_count),
median_N_count = median(Ns_count),
perc_with_Ns = sum(Ns_count > 0) / n() * 100
)
View(family_summary)
View(file_results)
View(family_summary)
View(all_data)
# Summarize the data by family
family_summary <- all_data %>%
group_by(family) %>%
summarise(
num_sequences = n(),
mean_N_count = mean(Ns_count),
median_N_count = median(Ns_count),
perc_with_Ns = sum(Ns_count > 0) / num_sequences * 100
)
View(family_summary)
# Select the top 20 families with the highest normalized mean N count
top_20_families <- family_summary %>%
arrange(desc(median_N_count)) %>%
head(20)
# Create a bar plot for the top 20 families
ggplot(top_20_families, aes(x = reorder(family, -median_N_count), y = median_N_count)) +
geom_bar(stat = "identity") +
labs(title = "Top 20 Families with Highest Mean N Count",
x = "Family",
y = "Mean N Count") +
theme(axis.text.x = element_text(angle = 90, hjust = 1)) +  # Rotate x-axis labels
geom_text(aes(label = perc_with_Ns), vjust = -0.5)  # Add sequence count as labels above the bars
# Create a bar plot for the top 20 families
library(ggplot2)
ggplot(top_20_families, aes(x = reorder(family, -median_N_count), y = median_N_count)) +
geom_bar(stat = "identity") +
labs(title = "Top 20 Families with Highest Mean N Count",
x = "Family",
y = "Mean N Count") +
theme(axis.text.x = element_text(angle = 90, hjust = 1)) +  # Rotate x-axis labels
geom_text(aes(label = perc_with_Ns), vjust = -0.5)  # Add sequence count as labels above the bars
# Summarize the data by family
family_summary <- all_data %>%
group_by(family) %>%
summarise(
num_sequences = n(),
mean_N_count = mean(Ns_count),
median_N_count = median(Ns_count),
percent_with_N = round(sum(Ns_count > 0) / num_sequences * 100, 2)
)
View(family_summary)
# Select the top 20 families with the highest normalized mean N count
top_20_families <- family_summary %>%
arrange(desc(median_N_count)) %>%
head(20)
# Create a bar plot for the top 20 families
library(ggplot2)
ggplot(top_20_families, aes(x = reorder(family, -median_N_count), y = median_N_count)) +
geom_bar(stat = "identity") +
labs(title = "Top 20 Families with Highest Mean N Count",
x = "Family",
y = "Mean N Count") +
theme(axis.text.x = element_text(angle = 90, hjust = 1)) +  # Rotate x-axis labels
geom_text(aes(label = perc_with_Ns), vjust = -0.5)  # Add sequence count as labels above the bars
ggplot(top_20_families, aes(x = reorder(family, -median_N_count), y = median_N_count)) +
geom_bar(stat = "identity") +
labs(title = "Top 20 Families with Highest Mean N Count",
x = "Family",
y = "Mean N Count") +
theme(axis.text.x = element_text(angle = 90, hjust = 1)) +  # Rotate x-axis labels
geom_text(aes(label = percent_with_Ns), vjust = -0.5)  # Add sequence count as labels above the bars
# Summarize the data by family
family_summary <- all_data %>%
group_by(family) %>%
summarise(
num_sequences = n(),
mean_N_count = mean(Ns_count),
median_N_count = median(Ns_count),
percent_with_Ns = round(sum(Ns_count > 0) / num_sequences * 100, 2)
)
ggplot(top_20_families, aes(x = reorder(family, -median_N_count), y = median_N_count)) +
geom_bar(stat = "identity") +
labs(title = "Top 20 Families with Highest Mean N Count",
x = "Family",
y = "Mean N Count") +
theme(axis.text.x = element_text(angle = 90, hjust = 1)) +  # Rotate x-axis labels
geom_text(aes(label = percent_with_Ns), vjust = -0.5)  # Add sequence count as labels above the bars
# Summarize the data by family
family_summary <- all_data %>%
group_by(family) %>%
summarise(
num_sequences = n(),
mean_N_count = mean(Ns_count),
median_N_count = median(Ns_count),
percent_with_Ns = round(sum(Ns_count > 0) / num_sequences * 100, 2)
)
ggplot(top_20_families, aes(x = reorder(family, -median_N_count), y = median_N_count)) +
geom_bar(stat = "identity") +
labs(title = "Top 20 Families with Highest Mean N Count",
x = "Family",
y = "Mean N Count") +
theme(axis.text.x = element_text(angle = 90, hjust = 1)) +  # Rotate x-axis labels
geom_text(aes(label = percent_with_Ns), vjust = -0.5)  # Add sequence count as labels above the bars
View(family_summary)
# Select the top 20 families with the highest normalized mean N count
top_20_families <- family_summary %>%
arrange(desc(median_N_count)) %>%
head(20)
ggplot(top_20_families, aes(x = reorder(family, -median_N_count), y = median_N_count)) +
geom_bar(stat = "identity") +
labs(title = "Top 20 Families with Highest Mean N Count",
x = "Family",
y = "Mean N Count") +
theme(axis.text.x = element_text(angle = 90, hjust = 1)) +  # Rotate x-axis labels
geom_text(aes(label = percent_with_Ns), vjust = -0.5)  # Add sequence count as labels above the bars
# Filter the family with the highest median_N_count (non-zero median)
high_median_family <- family_summary %>%
filter(median_N_count > 0) %>%
arrange(desc(median_N_count)) %>%
slice(1)
View(high_median_family)
# Select 19 families with median_N_count == 0 and highest percent_with_N
top_percent_families <- family_summary %>%
filter(median_N_count == 0) %>%
arrange(desc(percent_with_N)) %>%
slice_head(n = 19)
# Select 19 families with median_N_count == 0 and highest percent_with_N
top_percent_families <- family_summary %>%
filter(median_N_count == 0) %>%
arrange(desc(percent_with_Ns)) %>%
slice_head(n = 19)
top_20_families <- bind_rows(high_median_family, top_percent_families)
View(top_20_families)
ggplot(top_20_families, aes(x = reorder(family, -median_N_count), y = median_N_count)) +
geom_bar(stat = "identity") +
labs(title = "Top 20 Families with Highest Mean N Count",
x = "Family",
y = "Mean N Count") +
theme(axis.text.x = element_text(angle = 90, hjust = 1)) +  # Rotate x-axis labels
geom_text(aes(label = percent_with_Ns), vjust = -0.5)  # Add sequence count as labels above the bars
# Reorder the family factor based on conditions
top_20_families <- top_20_families %>%
mutate(
family = factor(
family,
levels = c(
# Start with the family with a non-zero median
high_median_family$family,
# Then add the remaining families sorted by percent_with_N
top_percent_families %>%
arrange(desc(percent_with_Ns)) %>%
pull(family)
)
)
)
# Plot
ggplot(top_20_families, aes(x = family, y = median_N_count)) +
geom_bar(stat = "identity") +
labs(
title = "Top 20 Families with Highest Median N Count",
x = "Family",
y = "Median N Count"
) +
theme(axis.text.x = element_text(angle = 90, hjust = 1)) +  # Rotate x-axis labels
geom_text(aes(label = paste0(round(percent_with_Ns, 2), "%")), vjust = -0.5)  # Add percentage labels above bars
library(seqinr)
library(dplyr)
library(ggplot2)
# Function to count Ns in sequences
count_Ns <- function(fasta_file) {
sequences <- read.fasta(fasta_file)  # Read the FASTA file
Ns_count <- sapply(sequences, function(seq) sum(toupper(seq) == "N"))  # Count 'N's in each sequence
return(Ns_count)
}
# Load all downloaded FASTA files
fasta_files <- list.files(path = "/Users/pablo/R/viralingo/nscounts_family_distribution/sequences", pattern = "*.fasta", full.names = TRUE)
# Initialize a list to store results
results <- list()
# Loop through each file and process
for (file in fasta_files) {
Ns_count <- count_Ns(file)  # Get the count of 'N's in each sequence
sequence_headers <- names(read.fasta(file))  # Get the headers (virus family info should be here)
# Extract viral family information from headers
family <- gsub(" .*", "", sequence_headers)
# Combine results into a data frame
file_results <- data.frame(file = rep(file, length(Ns_count)),
family = family,
Ns_count = Ns_count)
# Append to results list
results[[file]] <- file_results
}
# Combine all results into one data frame
all_data <- bind_rows(results)
# Summarize the data by family
family_summary <- all_data %>%
group_by(family) %>%
summarise(
num_sequences = n(),
mean_N_count = mean(Ns_count),
median_N_count = median(Ns_count),
percent_with_Ns = round(sum(Ns_count > 0) / num_sequences * 100, 2)
)
View(family_summary)
# Filter the family with the highest median_N_count (non-zero median)
high_median_family <- family_summary %>%
filter(median_N_count > 0) %>%
arrange(desc(median_N_count)) %>%
slice(1)
# Select 19 families with median_N_count == 0 and highest percent_with_N
top_percent_families <- family_summary %>%
filter(median_N_count == 0) %>%
arrange(desc(percent_with_Ns)) %>%
slice_head(n = 19)
top_20_families <- bind_rows(high_median_family, top_percent_families)
# Select the top 20 families with the highest normalized mean N count
top_20_families <- family_summary %>%
arrange(desc(median_N_count)) %>%
head(20)
# Reorder the family factor based on conditions
top_20_families <- top_20_families %>%
mutate(
family = factor(
family,
levels = c(
# Start with the family with a non-zero median
high_median_family$family,
# Then add the remaining families sorted by percent_with_N
top_percent_families %>%
arrange(desc(percent_with_Ns)) %>%
pull(family)
)
)
)
# Plot
ggplot(top_20_families, aes(x = family, y = median_N_count)) +
geom_bar(stat = "identity") +
labs(
title = "Top 20 Families with Highest Median N Count",
x = "Family",
y = "Median N Count"
) +
theme(axis.text.x = element_text(angle = 90, hjust = 1)) +  # Rotate x-axis labels
geom_text(aes(label = paste0(round(percent_with_Ns, 2), "%")), vjust = -0.5)  # Add percentage labels above bars
# Sort by percentage of sequences with Ns, and take top 20
top_20_families <- family_summary %>%
arrange(desc(percent_with_Ns)) %>%
head(20)
# Create a bar plot for the top 20 families with highest percentage of Ns
ggplot(top_20_families, aes(x = reorder(family, -percent_with_Ns), y = percent_with_Ns)) +
geom_bar(stat = "identity", fill = "skyblue") +
labs(x = "Viral Family", y = "Percentage of Sequences with Ns (%)", title = "Top 20 Viral Families with Highest Percentage of Ns") +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) # Rotate x-axis labels for readability
# Create a bar plot for the top 20 families with highest percentage of Ns
ggplot(top_20_families, aes(x = reorder(family, -percent_with_Ns), y = percent_with_Ns)) +
geom_bar(stat = "identity", fill = "skyblue") +
geom_text(aes(label = median_N_count), vjust = -0.5, color = "black", size = 3.5) +
labs(x = "Viral Family", y = "Percentage of Sequences with Ns (%)", title = "Top 20 Viral Families with Highest Percentage of Ns") +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) # Rotate x-axis labels for readability
# Create a bar plot for the top 20 families with highest percentage of Ns
ggplot(top_20_families, aes(x = reorder(family, -percent_with_Ns), y = percent_with_Ns)) +
geom_bar(stat = "identity", aes(fill = ifelse(median_N_count > 0, "red", "darkgrey"))) +
geom_text(aes(label = median_N_count), vjust = -0.5, color = "black", size = 3.5) +
labs(x = "Viral Family", y = "Percentage of Sequences with Ns (%)", title = "Top 20 Viral Families with Highest Percentage of Ns and Ns Counts Medians") +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) # Rotate x-axis labels for readability
# Create a bar plot for the top 20 families with highest percentage of Ns
ggplot(top_20_families, aes(x = reorder(family, -percent_with_Ns), y = percent_with_Ns)) +
geom_bar(stat = "identity", aes(fill = ifelse(median_N_count > 0, "red", "darkgrey"))) +
geom_text(aes(label = median_N_count), vjust = -0.5, color = "black", size = 3.5) +
scale_fill_identity() +
labs(x = "Viral Family", y = "Percentage of Sequences with Ns (%)", title = "Top 20 Viral Families with Highest Percentage of Ns and Ns Counts Medians") +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) # Rotate x-axis labels for readability
View(family_summary)
View(family_summary)
View(family_summary)
write.csv(family_summary, file = "/Users/pablo/R/viralingo/family_summary.csv", row.names = FALSE)
