library(devtools)
# Now let's work with a more complicated dataset
library(tissuesGeneExpression)
data(tissuesGeneExpression)
set.seed(1)
ind <- sample(nrow(e),500) #for simplicity use 500 rows (genes) chosen randomly
Y <- t(apply(e[ind,],1,scale)) #apply scale to the 500 samples. 1 specifies rows. Scale standardizes each gene to have mean of 0 and a std deviation of 1. Transpose is used to ensure that each row corresponds to one gene.
s <- svd(Y) #perform SVD
U <- s$u #extract the left singular vectors. U is a matrix where each column corresponds to a singular vector
V <- s$v #extract the right singular vectors
D <- diag(s$d) #convert the vector of singular values s$d into a diagonal matrix D. The off-diagonal elements are zeros
# We can reconstruct the original matrix Y to check if SVD did the right thing
Yhat <- U %*% D %*% t(V)
resid <- Y - Yhat #calculate residuals (differences between the original matrix Y and the reconstructed matrix Yhat)
max(abs(resid)) #find the maximum value among all the absolute residuals, which represents the largest deviation between the original and reconstructed matrices. Ideally this should be very close to zero
plot(s$d)
View(s)
# We can remove the last 4 columns to get rid of some dimensions
k <- ncol(U)-4
Yhat <- U[,1:k] %*% D[1:k,1:k] %*% t(V[1:k]) #recontstuct Yhat by selecting k submatrix
# Let's simulate a dataset
library(rafalib) #easier and more aesthetic plotting
library(MASS) #
n <- 100 #number of samples
set.seed(1) #ensure reproducibility (random numbers will be the same each time you run the code)
y <- t(mvrnorm(n,c(0,0), matrix(c(1,0.95,0.95,1),2,2))) #generate n samples of two-dimensional normally distributed data
mypar()
LIM <- c(-3.5,3.5)
plot(y[1,],y[2,],xlim=LIM,ylim=LIM) #plot original data
s <- svd(y) #decompose data using SVD. It originates singular vectors, which correspond to the directions of maximum variance in the data
PC1 <- s$d[1]*s$v[,1] #captures the most variance
PC2 <- s$d[2]*s$v[,2] #captures the second most variance
plot(PC1,PC2,xlim=LIM,ylim=LIM) #plot the data along its principal components
# Now let's work with a more complicated dataset
library(tissuesGeneExpression)
data(tissuesGeneExpression)
set.seed(1)
ind <- sample(nrow(e),500) #for simplicity use 500 rows (genes) chosen randomly
Y <- t(apply(e[ind,],1,scale)) #apply scale to the 500 samples. 1 specifies rows. Scale standardizes each gene to have mean of 0 and a std deviation of 1. Transpose is used to ensure that each row corresponds to one gene.
s <- svd(Y) #perform SVD
U <- s$u #extract the left singular vectors. U is a matrix where each column corresponds to a singular vector
V <- s$v #extract the right singular vectors
D <- diag(s$d) #convert the vector of singular values s$d into a diagonal matrix D. The off-diagonal elements are zeros
# We can reconstruct the original matrix Y to check if SVD did the right thing
Yhat <- U %*% D %*% t(V)
resid <- Y - Yhat #calculate residuals (differences between the original matrix Y and the reconstructed matrix Yhat)
max(abs(resid)) #find the maximum value among all the absolute residuals, which represents the largest deviation between the original and reconstructed matrices. Ideally this should be very close to zero
plot(s$d) #plotting the values we can see that there are some that are zeros, so we can make some dimensional reductions
# We can remove the last 4 columns to get rid of some dimensions
k <- ncol(U)-4
Yhat <- U[,1:k] %*% D[1:k,1:k] %*% t(V[1:k]) #recontstuct Yhat by selecting k submatrix
Yhat <- U[,1:k] %*% D[1:k,1:k] %*% t(V[,1:k]) #recontsruct Yhat by selecting k submatrix
resid <- Y - Yhat
max(abs(resid))
# The entries of d tell us the proportion of variance that is explained by that particular column
plot( s$d / sum(s$d^2)* 100)
# The entries of d tell us the proportion of variance that is explained by that particular column
plot( s$d^2 / sum(s$d^2)* 100)
# We can remove half of the data
k <- ncol(U)-95
Yhat <- U[,1:k] %*% D[1:k,1:k] %*% t(V[,1:k]) #reconstruct Yhat by selecting k submatrix
resid <- Y - Yhat
boxplot(resid, ylim=LIM)
# We can answer what percent we keep by
var(as.vector(resid))/var(as.vector(Y))
1-var(as.vector(resid))/var(as.vector(Y))
# We can also check like this
sum(s$d[1:k]^2/sum(s$d^2)
# We can also check like this
sum(s$d[1:k]^2/sum(s$d^2))
(s$d[1:k]^2/sum(s$d^2))
sum(s$d[1:k]^2/sum(s$d^2))
library(tissuesGeneExpression)
data(tissuesGeneExpression)
# Compute the SVD of e
s = svd(e)
# Now compute the mean of each row
m = rowMeans(e)
cor(s$u[,1],m)
newmeans = rnorm(nrow(e)) ##random values we will add to create new means
newe = e+newmeans ##we change the means
sqrt(crossprod(e[,3]-e[,45]))
sqrt(crossprod(newe[,3]-newe[,45]))
y = e - rowMeans(e)
s = svd(y)
resid = y - s$u %*% diag(s$d) %*% t(s$v)
max(abs(resid))
x=matrix(rep(c(1,2),each=5),5,2)
x
x*c(1:5)
sweep(x,1,1:5,"*")
# Which of the following gives us the same as diag(s$d)%*%t(s$v) ?
diag(s$d)%*%t(s$v)
# Which of the following gives us the same as diag(s$d)%*%t(s$v) ?
1-diag(s$d)%*%t(s$v)
# Which of the following gives us the same as diag(s$d)%*%t(s$v) ?
diag(s$d)%*%t(s$v)
s$d * t(s$v)
s$v % s$d
s$v * s$d
t(s$d * s$v)
s$d %*% t(s$v)[,1]
str(s$d)
str(s$v)
str(s$u)
is.matrix(s%d)
is.matrix(s$d)
is.matrix(s$v)
is.matrix(s$u)
# Let z = s$d * t(s$v). We showed a derivation demonstrating that because U is orthogonal,
# the distance between e[,3] and e[,45] is the same as the distance between y[,3] and y[,45],
# which is the same as z[,3] and z[,45]:
z = s$d * t(s$v)
sqrt(crossprod(e[,3]-e[,45]))
sqrt(crossprod(y[,3]-y[,45]))
sqrt(crossprod(z[,3]-z[,45]))
# What is the difference (in absolute value) between the actual distance
# sqrt(crossprod(e[,3]-e[,45])) and the approximation using only two dimensions of z?
z_2d <- z[1:2, ]
e_approx_3 <- s$u[, 1:2] %*% z_approx[, 3]
e_approx_45 <- s$u[, 1:2] %*% z_approx[, 45]
e_approx_3 <- s$u[, 1:2] %*% z_2d[, 3]
e_approx_45 <- s$u[, 1:2] %*% z_2d[, 45]
approx_distance <- sqrt(crossprod(e_approx_3 - e_approx_45))
abs(actual_distance - approx_distance)
abs(sqrt(crossprod(e[,3]-e[,45])) - approx_distance)
# What is the difference (in absolute value) between the actual distance
# sqrt(crossprod(e[,3]-e[,45])) and the approximation using only two dimensions of z?
realdistance = sqrt(crossprod(e[,3]-e[,45]))
approxdistance = sqrt(crossprod(z[1:2,3]-z[1:2,45]))
abs(realdistance - approxdistance)
#5# What is the minimum number of dimensions we need to use for the approximation
# in SVD Exercises #4 to be within 10% or less?
ks = 1:189
realdistance = sqrt(crossprod(e[,3]-e[,45]))
approxdistances = sapply(ks,function(k){
sqrt(crossprod(z[1:k,3,drop=FALSE]-z[1:k,45,drop=FALSE] ))
})
percentdiff = 100*abs(approxdistances - realdistance)/realdistance
plot(ks,percentdiff) ##take a look
min(ks[which(percentdiff < 10)])
install.packages("httr")
install.packages("xml2")
install.packages("tidyverse")
library(tidyverse)
library(httr) #enables interaction with the NCBI E-utilities API
library(xml2) #enables to extract info from XML formats
head("influenza_a_virus.fasta")
query <- "Influenza A virus[ORGANISM] AND 8000:20000[Sequence Length]"
ids <- search_ncbi(query, retmax = 10)
setwd("~/Downloads")
library(knitr)
library(VariantAnnotation)
library(tidyverse)
source(params$ext_funcs)
vcf <- readVcf(params$vcf)
head(rowRanges(vcf))
head(info(vcf))
head(geno(vcf)$GT)
View(vcf)
variants <- rowRanges(vcf)
variants$`REF` <- as.character(variants$`REF`)
variants$ALT <- sapply(variants$ALT, function(x) as.character(x)[1])
variants <- as_tibble(variants)
variants$variantName = names(rowRanges(vcf))
variants = cbind(variants, as_tibble(geno(vcf)$GT))
names(variants)[names(variants) == "patient_01_sample_01"] <- "case_case1"
names(variants)[names(variants) == "patient_02_sample_02"] <- "control_control1"
variants$gene <- unlist(lapply(info(vcf)$ANN, get_most_severe_gene))
variants$ens <- unlist(lapply(info(vcf)$ANN, get_most_severe_ens))
variants$transcript <- unlist(lapply(info(vcf)$ANN, get_most_severe_tr))
variants$aa_change <- unlist(lapply(info(vcf)$ANN, get_most_severe_aa_change))
variants$consequence <- unlist(lapply(info(vcf)$ANN, get_most_severe_consequence))
variants$impact <- unlist(lapply(info(vcf)$ANN, get_most_severe_impact))
View(variants)
variants %>%
filter(!is.na(consequence)) %>%
count(consequence) %>%
mutate(count = n,
percent = paste0(round(count/sum(count) * 100, digits = 2), "%"))%>%
arrange(desc(count)) %>%
mutate(lab.ypos = cumsum(count) - 0.5 * count) %>%
ggplot(aes(x="", y=count, fill=consequence))+
geom_bar(width = 1, stat = "identity")+
coord_polar(theta = "y")+
ggrepel::geom_text_repel(aes(y=lab.ypos, label=percent), max.overlaps = Inf)+
theme_void()
variants %>%
filter(!is.na(consequence)) %>%
group_by(consequence) %>%
summarise(count=n()) %>%
arrange(desc(count)) %>%
kable()
selectedVars <- filteredVars %>%
dplyr::select(seqnames, start, REF, ALT, gene, consequence, aa_change)
filteredVars = variants %>%
filter(control_control1 == "0/0" &
(impact == "MODERATE" | impact == "HIGH") &
# ens %in% significant_de_genes &
consequence == "missense_variant")
filteredVars <- as_tibble(filteredVars)
View(filteredVars)
selectedVars <- filteredVars %>%
dplyr::select(seqnames, start, REF, ALT, gene, consequence, aa_change)
selectedVars_table <- selectedVars
selectedVars_table %>% knitr::kable()
# create table for VEP
VEP.tab <- filteredVars %>%
dplyr::select(seqnames, start, REF, ALT) %>%
mutate(ID = ".",  .after = start) %>%
mutate(seqnames = substr(seqnames, 4, nchar(.))) # all are from chromosome 21 and VEP does not accept "chr"
write.table(VEP.tab, "table_to_VEP.txt", col.names = F, row.names = F, quote = FALSE)
VEP.res <- read.table("heTqTeW6D9L4Am4S.txt", header = T, sep ='\t',comment.char = "")
selectedVars_table <- VEP.res %>% filter(am_class %in% c("ambiguous", "likely_pathogenic"))
selectedVars_table %>%
select(Location, Consequence, SYMBOL, SIFT, PolyPhen, am_class, am_pathogenicity, LOEUF) %>%
knitr::kable()
write.table(selectedVars_table, "VEP_filtered_results_ex1_test.txt", row.names = F, quote = FALSE)
