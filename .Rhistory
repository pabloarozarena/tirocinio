library(devtools)
# Now let's work with a more complicated dataset
library(tissuesGeneExpression)
data(tissuesGeneExpression)
set.seed(1)
ind <- sample(nrow(e),500) #for simplicity use 500 rows (genes) chosen randomly
Y <- t(apply(e[ind,],1,scale)) #apply scale to the 500 samples. 1 specifies rows. Scale standardizes each gene to have mean of 0 and a std deviation of 1. Transpose is used to ensure that each row corresponds to one gene.
s <- svd(Y) #perform SVD
U <- s$u #extract the left singular vectors. U is a matrix where each column corresponds to a singular vector
V <- s$v #extract the right singular vectors
D <- diag(s$d) #convert the vector of singular values s$d into a diagonal matrix D. The off-diagonal elements are zeros
# We can reconstruct the original matrix Y to check if SVD did the right thing
Yhat <- U %*% D %*% t(V)
resid <- Y - Yhat #calculate residuals (differences between the original matrix Y and the reconstructed matrix Yhat)
max(abs(resid)) #find the maximum value among all the absolute residuals, which represents the largest deviation between the original and reconstructed matrices. Ideally this should be very close to zero
plot(s$d)
View(s)
# We can remove the last 4 columns to get rid of some dimensions
k <- ncol(U)-4
Yhat <- U[,1:k] %*% D[1:k,1:k] %*% t(V[1:k]) #recontstuct Yhat by selecting k submatrix
# Let's simulate a dataset
library(rafalib) #easier and more aesthetic plotting
library(MASS) #
n <- 100 #number of samples
set.seed(1) #ensure reproducibility (random numbers will be the same each time you run the code)
y <- t(mvrnorm(n,c(0,0), matrix(c(1,0.95,0.95,1),2,2))) #generate n samples of two-dimensional normally distributed data
mypar()
LIM <- c(-3.5,3.5)
plot(y[1,],y[2,],xlim=LIM,ylim=LIM) #plot original data
s <- svd(y) #decompose data using SVD. It originates singular vectors, which correspond to the directions of maximum variance in the data
PC1 <- s$d[1]*s$v[,1] #captures the most variance
PC2 <- s$d[2]*s$v[,2] #captures the second most variance
plot(PC1,PC2,xlim=LIM,ylim=LIM) #plot the data along its principal components
# Now let's work with a more complicated dataset
library(tissuesGeneExpression)
data(tissuesGeneExpression)
set.seed(1)
ind <- sample(nrow(e),500) #for simplicity use 500 rows (genes) chosen randomly
Y <- t(apply(e[ind,],1,scale)) #apply scale to the 500 samples. 1 specifies rows. Scale standardizes each gene to have mean of 0 and a std deviation of 1. Transpose is used to ensure that each row corresponds to one gene.
s <- svd(Y) #perform SVD
U <- s$u #extract the left singular vectors. U is a matrix where each column corresponds to a singular vector
V <- s$v #extract the right singular vectors
D <- diag(s$d) #convert the vector of singular values s$d into a diagonal matrix D. The off-diagonal elements are zeros
# We can reconstruct the original matrix Y to check if SVD did the right thing
Yhat <- U %*% D %*% t(V)
resid <- Y - Yhat #calculate residuals (differences between the original matrix Y and the reconstructed matrix Yhat)
max(abs(resid)) #find the maximum value among all the absolute residuals, which represents the largest deviation between the original and reconstructed matrices. Ideally this should be very close to zero
plot(s$d) #plotting the values we can see that there are some that are zeros, so we can make some dimensional reductions
# We can remove the last 4 columns to get rid of some dimensions
k <- ncol(U)-4
Yhat <- U[,1:k] %*% D[1:k,1:k] %*% t(V[1:k]) #recontstuct Yhat by selecting k submatrix
Yhat <- U[,1:k] %*% D[1:k,1:k] %*% t(V[,1:k]) #recontsruct Yhat by selecting k submatrix
resid <- Y - Yhat
max(abs(resid))
# The entries of d tell us the proportion of variance that is explained by that particular column
plot( s$d / sum(s$d^2)* 100)
# The entries of d tell us the proportion of variance that is explained by that particular column
plot( s$d^2 / sum(s$d^2)* 100)
# We can remove half of the data
k <- ncol(U)-95
Yhat <- U[,1:k] %*% D[1:k,1:k] %*% t(V[,1:k]) #reconstruct Yhat by selecting k submatrix
resid <- Y - Yhat
boxplot(resid, ylim=LIM)
# We can answer what percent we keep by
var(as.vector(resid))/var(as.vector(Y))
1-var(as.vector(resid))/var(as.vector(Y))
# We can also check like this
sum(s$d[1:k]^2/sum(s$d^2)
# We can also check like this
sum(s$d[1:k]^2/sum(s$d^2))
(s$d[1:k]^2/sum(s$d^2))
sum(s$d[1:k]^2/sum(s$d^2))
library(tissuesGeneExpression)
data(tissuesGeneExpression)
# Compute the SVD of e
s = svd(e)
# Now compute the mean of each row
m = rowMeans(e)
cor(s$u[,1],m)
newmeans = rnorm(nrow(e)) ##random values we will add to create new means
newe = e+newmeans ##we change the means
sqrt(crossprod(e[,3]-e[,45]))
sqrt(crossprod(newe[,3]-newe[,45]))
y = e - rowMeans(e)
s = svd(y)
resid = y - s$u %*% diag(s$d) %*% t(s$v)
max(abs(resid))
x=matrix(rep(c(1,2),each=5),5,2)
x
x*c(1:5)
sweep(x,1,1:5,"*")
# Which of the following gives us the same as diag(s$d)%*%t(s$v) ?
diag(s$d)%*%t(s$v)
# Which of the following gives us the same as diag(s$d)%*%t(s$v) ?
1-diag(s$d)%*%t(s$v)
# Which of the following gives us the same as diag(s$d)%*%t(s$v) ?
diag(s$d)%*%t(s$v)
s$d * t(s$v)
s$v % s$d
s$v * s$d
t(s$d * s$v)
s$d %*% t(s$v)[,1]
str(s$d)
str(s$v)
str(s$u)
is.matrix(s%d)
is.matrix(s$d)
is.matrix(s$v)
is.matrix(s$u)
# Let z = s$d * t(s$v). We showed a derivation demonstrating that because U is orthogonal,
# the distance between e[,3] and e[,45] is the same as the distance between y[,3] and y[,45],
# which is the same as z[,3] and z[,45]:
z = s$d * t(s$v)
sqrt(crossprod(e[,3]-e[,45]))
sqrt(crossprod(y[,3]-y[,45]))
sqrt(crossprod(z[,3]-z[,45]))
# What is the difference (in absolute value) between the actual distance
# sqrt(crossprod(e[,3]-e[,45])) and the approximation using only two dimensions of z?
z_2d <- z[1:2, ]
e_approx_3 <- s$u[, 1:2] %*% z_approx[, 3]
e_approx_45 <- s$u[, 1:2] %*% z_approx[, 45]
e_approx_3 <- s$u[, 1:2] %*% z_2d[, 3]
e_approx_45 <- s$u[, 1:2] %*% z_2d[, 45]
approx_distance <- sqrt(crossprod(e_approx_3 - e_approx_45))
abs(actual_distance - approx_distance)
abs(sqrt(crossprod(e[,3]-e[,45])) - approx_distance)
# What is the difference (in absolute value) between the actual distance
# sqrt(crossprod(e[,3]-e[,45])) and the approximation using only two dimensions of z?
realdistance = sqrt(crossprod(e[,3]-e[,45]))
approxdistance = sqrt(crossprod(z[1:2,3]-z[1:2,45]))
abs(realdistance - approxdistance)
#5# What is the minimum number of dimensions we need to use for the approximation
# in SVD Exercises #4 to be within 10% or less?
ks = 1:189
realdistance = sqrt(crossprod(e[,3]-e[,45]))
approxdistances = sapply(ks,function(k){
sqrt(crossprod(z[1:k,3,drop=FALSE]-z[1:k,45,drop=FALSE] ))
})
percentdiff = 100*abs(approxdistances - realdistance)/realdistance
plot(ks,percentdiff) ##take a look
min(ks[which(percentdiff < 10)])
setwd("~/viralingo")
install.packages("httr")
install.packages("xml2")
library(httr)
library(xml2)
##### SEARCH IN NCBI DATABASE - ESearch ######
search_ncbi <- function(query, db "nuccore", retmax = 10) {
##### SEARCH IN NCBI DATABASE - ESearch ######
search_ncbi <- function(query, db = "nuccore", retmax = 10) {
base_url <- "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi"
response <- GET(base_url, query = list(
db = db,
term = query,
retmax = retmax,
retmode = "xml"
))
#extract IDs
xml <- content(response, as = "parsed")
ids <- xml_find_all(xml, ".//Id") %>% xml_text()
return(ids)
}
View(search_ncbi)
library(tidyverse)
install.packages("tidyverse")
library(tidyverse)
query <- "Influenza[Organism] AND Spain[Location]"
ids <- search_ncbi(query, retmax = 5)
print(paste("Found IDs:", paste(ids, collapse = ", ")))
query <- "Influenza[Organism]"
ids <- search_ncbi(query, retmax = 5)
print(paste("Found IDs:", paste(ids, collapse = ", ")))
library(tidyverse)
library(httr) #enables interaction with the NCBI E-utilities API
library(xml2) #enables to extract info from XML formats
##### SEARCH IN NCBI DATABASE - ESearch ######
search_ncbi <- function(query, db = "nuccore", retmax = 10) {
base_url <- "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi"
response <- GET(base_url, query = list(
db = db,
term = query,
retmax = retmax,
retmode = "xml"
))
#extract IDs
xml <- content(response, as = "parsed")
ids <- xml_find_all(xml, ".//Id") %>% xml_text()
return(ids)
}
# Function to fetch sequences (EFetch)
fetch_sequences <- function(ids, db = "nuccore", rettype = "fasta") {
base_url <- "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi"
id_string <- paste(ids, collapse = ",")
response <- GET(base_url, query = list(
db = db,
id = id_string,
rettype = rettype,
retmode = "text"
))
# Return the fetched data
return(content(response, as = "text"))
}
query <- "Influenza[Organism]"
ids <- search_ncbi(query, retmax = 5)
print(paste("Found IDs:", paste(ids, collapse = ", ")))
if (length(ids) > 0) {
fasta_data <- fetch_sequences(ids)
writeLines(fasta_data, "influenza_sequences.fasta") # Save to a file
print("FASTA sequences saved to 'influenza_sequences.fasta'")
} else {
print("No IDs found.")
}
query <- "Acidianus bottle-shaped virus 2 strain ABV2[Organism]"
ids <- search_ncbi(query, retmax = 5)
print(paste("Found IDs:", paste(ids, collapse = ", ")))
if (length(ids) > 0) {
fasta_data <- fetch_sequences(ids)
writeLines(fasta_data, "influenza_sequences.fasta") # Save to a file
print("FASTA sequences saved to 'influenza_sequences.fasta'")
} else {
print("No IDs found.")
}
query <- "Influenza A virus[Organism], 12000:14000[Sequence Length]"
ids <- search_ncbi(query, retmax = 5)
print(paste("Found IDs:", paste(ids, collapse = ", ")))
if (length(ids) > 0) {
fasta_data <- fetch_sequences(ids)
writeLines(fasta_data, "influenza_sequences2.fasta") # Save to a file
print("FASTA sequences saved to 'influenza_sequences.fasta'")
} else {
print("No IDs found.")
}
query <- "Influenza A virus[Organism], 8000:14000[Sequence Length]"
ids <- search_ncbi(query, retmax = 5)
print(paste("Found IDs:", paste(ids, collapse = ", ")))
query <- "Influenza A virus[Organism], 5000:14000[Sequence Length]"
ids <- search_ncbi(query, retmax = 5)
print(paste("Found IDs:", paste(ids, collapse = ", ")))
if (length(ids) > 0) {
fasta_data <- fetch_sequences(ids)
writeLines(fasta_data, "influenza_sequences3.fasta") # Save to a file
print("FASTA sequences saved to 'influenza_sequences.fasta'")
} else {
print("No IDs found.")
}
##### SEARCH IN NCBI DATABASE - ESearch ######
search_ncbi <- function(query, db = "nuccore", retmax = 10) #db virus could be used too
{
base_url <- "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi"
response <- GET(base_url, query = list(
db = db,
term = query,
retmax = retmax,
retmode = "xml"
))
#extract IDs
xml <- content(response, as = "parsed")
ids <- xml_find_all(xml, ".//Id") %>% xml_text()
return(ids)
}
View(search_ncbi)
View(search_ncbi)
search_ncbi <- function(query, db = "nuccore", retmax = 10)
{
base_url <- "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi"
response <- GET(base_url, query = list(
db = db,
term = query,
retmax = retmax,
retmode = "xml"
))
#extract IDs
xml <- content(response, as = "parsed")
ids <- xml_find_all(xml, ".//Id") %>% xml_text()
return(ids)
}
fetch_sequences <- function(ids, db = "nuccore", rettype = "fasta")
{
base_url <- "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi"
id_string <- paste(ids, collapse = ",")
response <- GET(base_url, query = list(
db = db,
id = id_string,
rettype = rettype,
retmode = "text"
))
return(content(response, as = "text"))
}
query <- "Influenza A virus[ORGANISM]"
ids <- search_ncbi(query, retmax = 10)
print(paste("Found IDs:", paste(ids, collapse = ", ")))
if (length(ids) > 0) {
fasta_data <- fetch_sequences(ids)
writeLines(fasta_data, "influenza_a_virus.fasta")
print("Sequences have been saved to 'influenza_a_virus.fasta'")
} else {
print("No IDs were found for the query.")
}
query <- "Influenza A virus[ORGANISM] AND 5000:[Sequence Length]"
ids <- search_ncbi(query, retmax = 10)
print(paste("Found IDs:", paste(ids, collapse = ", ")))
if (length(ids) > 0) {
fasta_data <- fetch_sequences(ids)
writeLines(fasta_data, "influenza_a_virus.fasta")
print("Sequences have been saved to 'influenza_a_virus.fasta'")
} else {
print("No IDs were found for the query.")
}
query <- "Influenza A virus[ORGANISM] AND 800:[Sequence Length]"
ids <- search_ncbi(query, retmax = 10)
print(paste("Found IDs:", paste(ids, collapse = ", ")))
if (length(ids) > 0) {
fasta_data <- fetch_sequences(ids)
writeLines(fasta_data, "influenza_a_virus_800bp.fasta")
print("Sequences have been saved to 'influenza_a_virus_800bp.fasta'")
} else {
print("No IDs were found for the query.")
}
search_ncbi <- function(query, db = "nuccore", retmax = 10)
{
base_url <- "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi"
response <- GET(base_url, query = list(
db = db,
term = query,
retmax = retmax,
retmode = "xml"
))
#extract IDs
xml <- content(response, as = "parsed")
ids <- xml_find_all(xml, ".//Id") %>% xml_text()
return(ids)
}
fetch_sequences <- function(ids, db = "nuccore", rettype = "fasta")
{
base_url <- "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi"
id_string <- paste(ids, collapse = ",")
response <- GET(base_url, query = list(
db = db,
id = id_string,
rettype = rettype,
retmode = "text"
))
return(content(response, as = "text"))
}
query <- "Influenza A virus[ORGANISM]"
search_ncbi <- function(query, db = "nuccore", retmax = 10)
{
base_url <- "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi"
response <- GET(base_url, query = list(
db = db,
term = query,
retmax = retmax,
retmode = "xml"
))
#extract IDs
xml <- content(response, as = "parsed")
ids <- xml_find_all(xml, ".//Id") %>% xml_text()
return(ids)
}
fetch_sequences <- function(ids, db = "nuccore", rettype = "fasta")
{
base_url <- "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi"
id_string <- paste(ids, collapse = ",")
response <- GET(base_url, query = list(
db = db,
id = id_string,
rettype = rettype,
retmode = "text"
))
return(content(response, as = "text"))
}
query <- "Influenza A virus[ORGANISM] AND 5000:[Sequence Length]"
ids <- search_ncbi(query, retmax = 10)
print(paste("Found IDs:", paste(ids, collapse = ", ")))
query <- "Influenza A virus[ORGANISM] AND 50:[Sequence Length]"
ids <- search_ncbi(query, retmax = 10)
print(paste("Found IDs:", paste(ids, collapse = ", ")))
query <- "Influenza A virus[ORGANISM] AND 50: [Sequence Length]"
ids <- search_ncbi(query, retmax = 10)
print(paste("Found IDs:", paste(ids, collapse = ", ")))
query <- "Influenza A virus[ORGANISM] AND 5000:20000[Sequence Length]"
ids <- search_ncbi(query, retmax = 10)
print(paste("Found IDs:", paste(ids, collapse = ", ")))
if (length(ids) > 0) {
fasta_data <- fetch_sequences(ids)
writeLines(fasta_data, "influenza_a_virus_genomes.fasta")
print("Sequences have been saved to 'influenza_a_virus_genomes.fasta'")
} else {
print("No IDs were found for the query.")
}
source("~/viralingo/retrieve_ncbivirus_sequences.R")
install.packages("tidyverse")
install.packages("xml2")
install.packages("httr")
install.packages("xml2")
install.packages("tidyverse")
query <- "Influenza A virus[ORGANISM] AND 8000:20000[Sequence Length]"
query <- "Influenza A virus[ORGANISM] AND 8000:20000[Sequence Length]"
##library(tidyverse)
library(httr) #enables interaction with the NCBI E-utilities API
library(xml2) #enables to extract info from XML formats
search_ncbi <- function(query, db = "nuccore", retmax = 10)
{
base_url <- "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi"
response <- GET(base_url, query = list(
db = db,
term = query,
retmax = retmax,
retmode = "xml"
))
#extract IDs
xml <- content(response, as = "parsed")
ids <- xml_find_all(xml, ".//Id") %>% xml_text()
return(ids)
}
fetch_sequences <- function(ids, db = "nuccore", rettype = "fasta")
{
base_url <- "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi"
id_string <- paste(ids, collapse = ",")
response <- GET(base_url, query = list(
db = db,
id = id_string,
rettype = rettype,
retmode = "text"
))
return(content(response, as = "text"))
}
query <- "Influenza A virus[ORGANISM]"
ids <- search_ncbi(query, retmax = 10)
print(paste("Found IDs:", paste(ids, collapse = ", ")))
if (length(ids) > 0) {
fasta_data <- fetch_sequences(ids)
writeLines(fasta_data, "influenza_a_virus.fasta")
print("Sequences have been saved to 'influenza_a_virus.fasta'")
} else {
print("No IDs were found for the query.")
}
##library(tidyverse)
library(httr) #enables interaction with the NCBI E-utilities API
library(xml2) #enables to extract info from XML formats
search_ncbi <- function(query, db = "nuccore", retmax = 10)
{
base_url <- "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi"
response <- GET(base_url, query = list(
db = db,
term = query,
retmax = retmax,
retmode = "xml"
))
#extract IDs
xml <- content(response, as = "parsed")
ids <- xml_find_all(xml, ".//Id") %>% xml_text()
return(ids)
}
#extract IDs
xml <- content(response, as = "parsed")
fetch_sequences <- function(ids, db = "nuccore", rettype = "fasta")
{
base_url <- "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi"
id_string <- paste(ids, collapse = ",")
response <- GET(base_url, query = list(
db = db,
id = id_string,
rettype = rettype,
retmode = "text"
))
return(content(response, as = "text"))
}
query <- "Influenza A virus[ORGANISM]"
ids <- search_ncbi(query, retmax = 10)
##library(tidyverse)
library(tidyverse)
ids <- search_ncbi(query, retmax = 10)
print(paste("Found IDs:", paste(ids, collapse = ", ")))
if (length(ids) > 0) {
fasta_data <- fetch_sequences(ids)
writeLines(fasta_data, "influenza_a_virus.fasta")
print("Sequences have been saved to 'influenza_a_virus.fasta'")
} else {
print("No IDs were found for the query.")
}
query <- "Influenza A virus[ORGANISM] AND 8000:20000[Sequence Length]"
ids <- search_ncbi(query, retmax = 10)
print(paste("Found IDs:", paste(ids, collapse = ", ")))
if (length(ids) > 0) {
fasta_data <- fetch_sequences(ids)
writeLines(fasta_data, "influenza_a_virus_genomes.fasta")
print("Sequences have been saved to 'influenza_a_virus_genome.fasta'")
} else {
print("No IDs were found for the query.")
}
